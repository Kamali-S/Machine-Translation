{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine_Translation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8p1pZtptRR3",
        "colab_type": "code",
        "outputId": "5079f447-4d50-454c-a34a-3846f23a2aa5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        }
      },
      "source": [
        "!pip install tensorflow==2.0.0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==2.0.0 in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.8.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.12.1)\n",
            "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (3.10.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (2.0.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.2.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.9.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.12.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (3.2.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.18.3)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.0.8)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.28.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.34.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.2.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (46.1.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.4.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.7.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0.0) (2.10.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (4.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5oOdVNkdL1w",
        "colab_type": "code",
        "outputId": "4aba0494-43a6-4ffc-ddbd-5bf586e61600",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kziiA6nBs65G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from string import digits\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9-X88J2PRAc",
        "colab_type": "code",
        "outputId": "bc16826f-cf9d-4abd-89ce-97a3e9123c44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "# Read the data\n",
        "df = pd.read_table(\"/content/drive/My Drive/french_to_english.txt\",names=['source', 'target', 'comments'])\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>target</th>\n",
              "      <th>comments</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Va !</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Salut !</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Salut.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Cours !</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Courez !</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  source    target                                           comments\n",
              "0    Go.      Va !  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
              "1    Hi.   Salut !  CC-BY 2.0 (France) Attribution: tatoeba.org #5...\n",
              "2    Hi.    Salut.  CC-BY 2.0 (France) Attribution: tatoeba.org #5...\n",
              "3   Run!   Cours !  CC-BY 2.0 (France) Attribution: tatoeba.org #9...\n",
              "4   Run!  Courez !  CC-BY 2.0 (France) Attribution: tatoeba.org #9..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4RtImUQrwDy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.iloc[0:50000,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWeW22FcwXwQ",
        "colab_type": "text"
      },
      "source": [
        "Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jn8F_mtKPioC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_digits= str.maketrans('','', digits)\n",
        "df.replace(to_replace=\" +\", value= \" \",  inplace=True, regex=True)\n",
        "df.replace(to_replace=\"([?.!,¿])\", value=\"\", inplace=True, regex=True )\n",
        "df['source'] = df.apply(lambda x: x['source'].translate(num_digits) ,axis = 1)\n",
        "df['source'] = df.apply(lambda x: x['source'].rstrip().strip() ,axis = 1)\n",
        "df['target'] = df.apply(lambda x: x['target'].translate(num_digits) ,axis = 1)\n",
        "df['target'] = df.apply(lambda x: x['target'].rstrip().strip() ,axis = 1)\n",
        "df['source'] = 'start ' + df['source'].astype(str) + ' end'\n",
        "df['target'] = 'start ' + df['target'].astype(str) + ' end'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYqdDhcSXoZK",
        "colab_type": "code",
        "outputId": "262e31c2-766b-43e9-ed64-93d603729293",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "# Cleaned data\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>target</th>\n",
              "      <th>comments</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>start Go end</td>\n",
              "      <td>start Va end</td>\n",
              "      <td>CC-BY 20 (France) Attribution: tatoebaorg #287...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>start Hi end</td>\n",
              "      <td>start Salut end</td>\n",
              "      <td>CC-BY 20 (France) Attribution: tatoebaorg #538...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>start Hi end</td>\n",
              "      <td>start Salut end</td>\n",
              "      <td>CC-BY 20 (France) Attribution: tatoebaorg #538...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>start Run end</td>\n",
              "      <td>start Cours end</td>\n",
              "      <td>CC-BY 20 (France) Attribution: tatoebaorg #906...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>start Run end</td>\n",
              "      <td>start Courez end</td>\n",
              "      <td>CC-BY 20 (France) Attribution: tatoebaorg #906...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          source  ...                                           comments\n",
              "0   start Go end  ...  CC-BY 20 (France) Attribution: tatoebaorg #287...\n",
              "1   start Hi end  ...  CC-BY 20 (France) Attribution: tatoebaorg #538...\n",
              "2   start Hi end  ...  CC-BY 20 (France) Attribution: tatoebaorg #538...\n",
              "3  start Run end  ...  CC-BY 20 (France) Attribution: tatoebaorg #906...\n",
              "4  start Run end  ...  CC-BY 20 (France) Attribution: tatoebaorg #906...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eK6KdhdhXxBr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.drop(['comments'], axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rDZh5ZLX10I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Finding maximum length of source text and target text for padding\n",
        "source = list(df['source'].values)\n",
        "target = list(df['target'].values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SxqO5CKYnxY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "length = list(map(lambda x: len(x.split()),source))\n",
        "source_max_length = max(length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-4sXI3gY_jf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "length = list(map(lambda x: len(x.split()),target))\n",
        "target_max_length = max(length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzmrujeAZE_m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converting input to sequence\n",
        "source_tokenizer= tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "source_tokenizer.fit_on_texts(source)\n",
        "source_seq = source_tokenizer.texts_to_sequences(source)\n",
        "source_seq = tf.keras.preprocessing.sequence.pad_sequences(source_seq,padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1uIU8nOfX0I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_tokenizer= tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "target_tokenizer.fit_on_texts(target)\n",
        "target_seq = target_tokenizer.texts_to_sequences(target)\n",
        "target_seq = tf.keras.preprocessing.sequence.pad_sequences(target_seq,padding='post' )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9gkE28mhZC5",
        "colab_type": "text"
      },
      "source": [
        "Creating training and testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7Tp86wHf3HN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "source_train, source_test, target_train, target_test = train_test_split(source_seq, target_seq,test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s16zbSD6gKPj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "source_val_train, source_val_test, target_val_train, target_val_test = train_test_split(source_seq, target_seq, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-ZlctGksPz0",
        "colab_type": "text"
      },
      "source": [
        "To give a visual of how each word is mapped to a number"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OA-uJZibiK4R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Index_to_Word_mapping(lang, tensor):\n",
        "  for t in tensor:\n",
        "    if t!=0:\n",
        "      print (\"%d ---->%s\" % (t, lang.index_word[t]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bKKUBd2i9u0",
        "colab_type": "code",
        "outputId": "cbb2ac69-65b5-4bd4-d272-cf19901a6e6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "print (\"Source Language: index to word mapping\")\n",
        "Index_to_Word_mapping(source_tokenizer, source_train[0])\n",
        "print ()\n",
        "print (\"Target Language: index to word mapping\")\n",
        "Index_to_Word_mapping( target_tokenizer, target_train[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Source Language: index to word mapping\n",
            "1 ---->start\n",
            "113 ---->leave\n",
            "14 ---->this\n",
            "9 ---->to\n",
            "13 ---->me\n",
            "2 ---->end\n",
            "\n",
            "Target Language: index to word mapping\n",
            "1 ---->start\n",
            "603 ---->laissez\n",
            "2 ---->end\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0FyjwEeke8H",
        "colab_type": "text"
      },
      "source": [
        "Building tensorflow Encoder-Decoder Attention Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pORJ-CZEjABW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating variables needed for the tf model\n",
        "buffer_size = len(source_train) # to create shuffled dataset with the corpus\n",
        "batch_size = 64\n",
        "steps_per_epoch = len(source_train)\n",
        "embedding_vec_dim = 256\n",
        "units = 1024\n",
        "source_vocab_size = len(source_tokenizer.word_index)+1\n",
        "target_vocab_size = len(target_tokenizer.word_index)+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhxWOAmJlW5-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf_df = tf.data.Dataset.from_tensor_slices((source_train, target_train)).shuffle(buffer_size)\n",
        "tf_df = tf_df.batch(batch_size, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjBBx-uooRrT",
        "colab_type": "text"
      },
      "source": [
        "**Encoder**\n",
        "\n",
        "Input->Embedding_layer->GRU->hidden_layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2_Z2PNj4Xwa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qaKnjs4pQU1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_source, sample_target = next(iter(tf_df))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxzdUW6qrlmu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = Encoder(source_vocab_size, embedding_vec_dim, units, batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8b7x4sRxfTa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_hidden = encoder.initialize_hidden_state()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCdmnd0yxscN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_output, sample_hidden = encoder(sample_source, sample_hidden)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vJVR_VMzaPp",
        "colab_type": "text"
      },
      "source": [
        "Building Attention part "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGs4MSA9yB0N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Attention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(Attention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    hidden_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(values) + self.W2(hidden_with_time_axis)))\n",
        "\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhURApd4yIR5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "attention_layer = Attention(10)\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Crm4yO9AzjSM",
        "colab_type": "text"
      },
      "source": [
        "Building Decoder Part"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciV4b6XXyN7-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    self.attention = Attention(self.dec_units)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "    x = self.embedding(x)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "    output, state = self.gru(x)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqE6KDNYyTMR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder = Decoder(target_vocab_size, embedding_vec_dim, units, batch_size)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((batch_size, 1)), sample_hidden, sample_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVaqovZaznpe",
        "colab_type": "text"
      },
      "source": [
        "Defining Optimizers and Loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37uaOcqgyq7i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bb_oxx5d72yf",
        "colab_type": "text"
      },
      "source": [
        "Checkpoints\n",
        "\n",
        "While Training, if any error occurs at some iteration, then all the weights calculated till that iteration will be lost.\n",
        "\n",
        "If we create checkpoints, we can store the weights by defining after how many epochs I need to save my model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5ELSjZl7x8a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = 'training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer, encoder=encoder, decoder=decoder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pR8sy_L40jX-",
        "colab_type": "text"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W24jbqkly1Sf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function # to avoid errors\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    dec_input = tf.expand_dims([target_tokenizer.word_index['start']] * batch_size, 1)\n",
        "\n",
        "    for t in range(1, targ.shape[1]):\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PddfjKU80y2m",
        "colab_type": "code",
        "outputId": "c9b75400-ce4d-4651-9d15-e65c9c2a1f17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        }
      },
      "source": [
        "import time\n",
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(tf_df.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "  print('Epoch =', epoch + 1,' Batch =',batch, 'loss =',batch_loss.numpy())\n",
        "   \n",
        "      \n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "  # if (epoch + 1) % 2 == 0:\n",
        "  checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch', epoch + 1, 'Loss', (total_loss / steps_per_epoch))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch = 1  Batch = 624 loss = 1.1143413\n",
            "Epoch 1 Loss tf.Tensor(0.02353998, shape=(), dtype=float32)\n",
            "Time taken for 1 epoch 2792.7101757526398 sec\n",
            "\n",
            "Epoch = 2  Batch = 624 loss = 0.7901312\n",
            "Epoch 2 Loss tf.Tensor(0.014027792, shape=(), dtype=float32)\n",
            "Time taken for 1 epoch 2670.784355163574 sec\n",
            "\n",
            "Epoch = 3  Batch = 624 loss = 0.4438149\n",
            "Epoch 3 Loss tf.Tensor(0.009164154, shape=(), dtype=float32)\n",
            "Time taken for 1 epoch 2674.553356409073 sec\n",
            "\n",
            "Epoch = 4  Batch = 624 loss = 0.4219109\n",
            "Epoch 4 Loss tf.Tensor(0.0064113326, shape=(), dtype=float32)\n",
            "Time taken for 1 epoch 2668.898288965225 sec\n",
            "\n",
            "Epoch = 5  Batch = 624 loss = 0.30115694\n",
            "Epoch 5 Loss tf.Tensor(0.004773234, shape=(), dtype=float32)\n",
            "Time taken for 1 epoch 2648.8732085227966 sec\n",
            "\n",
            "Epoch = 6  Batch = 624 loss = 0.23352095\n",
            "Epoch 6 Loss tf.Tensor(0.0037679768, shape=(), dtype=float32)\n",
            "Time taken for 1 epoch 2647.2204077243805 sec\n",
            "\n",
            "Epoch = 7  Batch = 624 loss = 0.23210058\n",
            "Epoch 7 Loss tf.Tensor(0.0031233924, shape=(), dtype=float32)\n",
            "Time taken for 1 epoch 2632.836765766144 sec\n",
            "\n",
            "Epoch = 8  Batch = 624 loss = 0.2026436\n",
            "Epoch 8 Loss tf.Tensor(0.002694818, shape=(), dtype=float32)\n",
            "Time taken for 1 epoch 2668.601943731308 sec\n",
            "\n",
            "Epoch = 9  Batch = 624 loss = 0.15127651\n",
            "Epoch 9 Loss tf.Tensor(0.0023998944, shape=(), dtype=float32)\n",
            "Time taken for 1 epoch 2883.5143852233887 sec\n",
            "\n",
            "Epoch = 10  Batch = 624 loss = 0.122124396\n",
            "Epoch 10 Loss tf.Tensor(0.0021881065, shape=(), dtype=float32)\n",
            "Time taken for 1 epoch 2979.5201699733734 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ru9LaPFXh17W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_sentence(sentence):\n",
        "    \n",
        "    num_digits= str.maketrans('','', digits)\n",
        "    \n",
        "    sentence= sentence.lower()\n",
        "    sentence= re.sub(\" +\", \" \", sentence)\n",
        "    sentence= re.sub(\"'\", '', sentence)\n",
        "    sentence= sentence.translate(num_digits)\n",
        "    sentence= re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence)\n",
        "    sentence = sentence.rstrip().strip()\n",
        "    sentence=  'start ' + sentence + ' end'\n",
        "    \n",
        "    return sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgbKd_aE3B2k",
        "colab_type": "text"
      },
      "source": [
        "Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3o-mi6xjPpOV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Translate(sentence):\n",
        "\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  inputs = [source_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=source_max_length, padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([target_tokenizer.word_index['start']], 0)\n",
        "\n",
        "  for t in range(target_max_length):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
        "\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "    result += target_tokenizer.index_word[predicted_id] + ' '\n",
        "\n",
        "    if target_tokenizer.index_word[predicted_id] == 'end':\n",
        "      return result, sentence\n",
        "\n",
        "    # the predicted ID is fed back into the model\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  return result, sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lp2XZZB0kFXo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "da189e8f-8a0f-4c3a-8f39-0b6a1b9b1d60"
      },
      "source": [
        "result, sentence = Translate(\"I am going to sleep\")\n",
        "print(result)\n",
        "print(sentence)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "je vais dormir end \n",
            "start i am going to sleep end\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3ORIRuX24Da",
        "colab_type": "text"
      },
      "source": [
        "Converting text to audio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9USNgZt7toK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "933dcf1f-443c-4579-b5f7-dc22f982591e"
      },
      "source": [
        "!pip install gTTS"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gTTS\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/0c/4ca77eca3b739a4a08360930643f58d714e302fee0d2f8c654e67d9af8e7/gTTS-2.1.1-py3-none-any.whl\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from gTTS) (7.1.2)\n",
            "Collecting gtts-token>=1.1.3\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/25/ca6e9cd3275bfc3097fe6b06cc31db6d3dfaf32e032e0f73fead9c9a03ce/gTTS-token-1.1.3.tar.gz\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from gTTS) (4.6.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gTTS) (1.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gTTS) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gTTS) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gTTS) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gTTS) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gTTS) (2.9)\n",
            "Building wheels for collected packages: gtts-token\n",
            "  Building wheel for gtts-token (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gtts-token: filename=gTTS_token-1.1.3-cp36-none-any.whl size=4097 sha256=52e7a89b7acff648c2d4e64b63302fff693f753264ee777d64fe778382901fe2\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/11/61/33f7e51bf545e910552b2255eead2a7cd8ef54064b46dceb34\n",
            "Successfully built gtts-token\n",
            "Installing collected packages: gtts-token, gTTS\n",
            "Successfully installed gTTS-2.1.1 gtts-token-1.1.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zB9xGTSf7umm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gtts import gTTS \n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaKRCSKz7uu5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "language = 'fr-FR'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IicxjUh7uss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "speech = gTTS(result, lang = language, slow = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vECAQoQQ7uqB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "speech.save(\"text.mp3\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRSAhsAC8cAZ",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"text.mp3\"> Download File </a>"
      ]
    }
  ]
}
